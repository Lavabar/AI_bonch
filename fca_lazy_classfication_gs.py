# -*- coding: utf-8 -*-
"""FCA_lazy_classfication_GS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JoS59SRcagUcwNTszHUtydDW-EaPML1M

#1. Problem statement
 
Banks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit. 
 
Credit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.
 
The goal of this project is to build a model that borrowers can use to help make the best financial decisions.
"""

# In[1]:
 
import numpy as np
import pandas as pd
import random
import sklearn
from sklearn import metrics
import sklearn.model_selection
import datetime
import time
import os
import math
random.seed(1)

"""#2. Dataset summary
 
Dataset of Kaggle's competition "Give Me Some Credit" was considered.
 
 https://www.kaggle.com/c/GiveMeSomeCredit
 
 Here's description of the features:
"""

!unzip GiveMeSomeCredit.zip

# In[2]:
 
data_dict = pd.read_excel('Data Dictionary.xls', header=1)
data_dict

# In[3]:
 
for ind in range(data_dict.shape[0]):
    print(data_dict.iloc[ind]['Variable Name'] + ' - '+data_dict.iloc[ind]['Description'], end="\n\n")

"""**SeriousDlqin2yrs** - target variable.
 
All the Kaggle's training dataset was divided in two parts (train 90% and test 10%) as long as there were no true values os the target variable in Kaggle's test set.
 
The proportion of + and - objects was hold.
 
Objects that contained missed values were excluded from the dataset in order to tune parameters of the main method better.
"""

# In[4]:
 
df = pd.read_csv('cs-training.csv', index_col=0).dropna()
 
 
# In[5]:
 
X = df.drop('SeriousDlqin2yrs', axis=1)
y = df['SeriousDlqin2yrs']
X.shape

# Dividing in **train** and **test**:
 
# In[6]:
 
df_pos = df[df['SeriousDlqin2yrs']==1].drop('SeriousDlqin2yrs',axis=1)
df_neg = df[df['SeriousDlqin2yrs']==0].drop('SeriousDlqin2yrs',axis=1)
df_test_pos = df_pos.sample(frac=0.1, random_state=1)
df_test_neg = df_neg.sample(frac=0.1, random_state=1)
df_train_pos = df_pos.drop(df_test_pos.index)
df_train_neg = df_neg.drop(df_test_neg.index)
df_test = df_test_pos.append(df_test_neg)
 
 
# In[7]:
 
#df_train_pos.to_csv('df_train_pos.csv')
#df_train_neg.to_csv('df_train_neg.csv')
#df_test.to_csv('df_test.csv')
 
 
# In[8]:
 
df_train_pos = pd.read_csv('df_train_pos.csv',index_col=0)
df_train_neg = pd.read_csv('df_train_neg.csv',index_col=0)
df_test= pd.read_csv('df_test.csv',index_col=0)

# In[9]:
 
df_train_pos.head()

# In[10]:
 
df_train_neg.shape

# In[11]:
 
X_pos = df_train_pos.values
X_neg = df_train_neg.values
X_test = df_test.values
y_true = y[df_test.index].values
X_neg_true = X_neg.copy()
 
 
# In[12]:
 
X_test.shape

# In[13]:
 
X.shape[0] - X_test.shape[0]

"""As a result there was *108242* obejcts in train dataset, *12027* objects in test dataset. Each of them contained 10 features.
 
#3. Methodology
 
The first (and the main) approach is described at 

*Masyutin A., Kashnitsky Y., Kuznetsov S. O. Lazy Classication with Interval Pattern Structures: Application to Credit Scoring, in: Proceedings of the International Workshop "What can FCA do for Artificial Intelligence?" (FCA4AI at IJCAI 2015) / Ed. by Sergei O. Kuznetsov, A. Napoli, S. Rudolph. Buenos Aires : , 2015. P. 43-54.*
 
This approach is considered in two small variations and compared with Logistic regression and Random forest.
 
#4. Experiment setup and results
 
Next, here is the code that executed many times with different parameters.
 
Creating dirs
"""

# In[12]:
 
N_OF_ITER = [100,200,1000]
ALPHA = [0.1]
SAMPLE_SIZES = [2,3,4,5,6,7,8,9,10]
 
for number_of_iterations in N_OF_ITER:
    for alpha in ALPHA:
        for subsample_size in SAMPLE_SIZES:
            os.system("mkdir "+str(number_of_iterations)+'_'+str(alpha)+'_'+str(subsample_size))

"""#MLCA (classic)

 The general moments of this approach are:
* All the test set is divided into 8 parts and processed separately with 8 ipython notebooks in order not to go into details of multithreading.
* Parameter "number of objects" is used instead of "sample size" as in original paper.
* Every iteration we extract a sample from negative context in order to save time. The quality decreased slightly.
"""

# In[77]:
 
N_OF_ITER = [2000]
ALPHA = [0.001]
SAMPLE_SIZES = [2]
MODIFICATION = ""
# MODIFICATION = "all_X_neg_"
 
 
for number_of_iterations in N_OF_ITER:
    for alpha in ALPHA:
        for subsample_size in SAMPLE_SIZES:
            os.system("mkdir "+ MODIFICATION + str(number_of_iterations)+'_'+str(alpha)+'_'+str(subsample_size))
 
NUMBER_OF_MINI_TEST = 0
 
mini_test_size = df_test.shape[0]//8
start_index = mini_test_size*NUMBER_OF_MINI_TEST
end_index = start_index+mini_test_size
mini_test_index = df_test.index[start_index:end_index]
 
# mini_test_size = 100
# mini_test_index = np.concatenate((df_test_pos.index[np.random.choice(df_test_pos.shape[0], size=mini_test_size, replace=False)],\
#             df_test_neg.index[np.random.choice(df_test_neg.shape[0], size=mini_test_size, replace=False)]))
 
for number_of_iterations in N_OF_ITER:
    for alpha in ALPHA:
        for subsample_size in SAMPLE_SIZES:
 
            NUMBER_OF_POS_VOTES = []
            NUMBER_OF_NEG_VOTES = []
            start_time = datetime.datetime.now()
            print("PARAMS: ", number_of_iterations, alpha, subsample_size)
            print("STARTED AT:", start_time.ctime())
            for test_index in mini_test_index:
                test_obj = df_test.loc[test_index].values
 
                neg_itersections_with_all_pos = np.zeros(number_of_iterations)
                pos_itersections_with_all_neg = np.zeros(number_of_iterations)
                # MODIFICATION = "all_X_neg_"
                X_neg = X_neg_true[np.random.choice(X_neg_true.shape[0], size=X_pos.shape[0], replace=False)] # 
                # MODIFICATION = "all_X_neg_"
 
                for i in range(number_of_iterations):    
 
                    pos_sample_ind = np.random.choice(X_pos.shape[0], size=subsample_size)
                    while np.unique(pos_sample_ind).shape[0]!=subsample_size:
                        pos_sample_ind = np.random.choice(X_pos.shape[0], size=subsample_size)
 
                    pos_sample = X_pos[pos_sample_ind]
                    premise_min = np.min((pos_sample.min(axis=0),test_obj), axis=0)
                    premise_max = np.max((pos_sample.max(axis=0),test_obj), axis=0)
                #     X_neg = X_neg_true[np.random.choice(X_neg_true.shape[0], size=X_pos.shape[0], replace=False)]
                    pos_itersections_with_all_neg[i]=np.sum((np.sum(X_neg <= premise_max, axis=1) == 10) & (np.sum(X_neg >= premise_min, axis=1) == 10))
                #     X_neg = X_neg_true
 
                    neg_sample_ind = np.random.choice(X_neg.shape[0], size=subsample_size)
                    while np.unique(neg_sample_ind).shape[0]!=subsample_size:
                        neg_sample_ind = np.random.choice(X_neg.shape[0], size=subsample_size)
 
                    neg_sample = X_neg[neg_sample_ind]
                    premise_min = np.min((neg_sample.min(axis=0),test_obj), axis=0)
                    premise_max = np.max((neg_sample.max(axis=0),test_obj), axis=0)
                    neg_itersections_with_all_pos[i]=np.sum((np.sum(X_pos <= premise_max, axis=1) == 10) & (np.sum(X_pos >= premise_min, axis=1) == 10))
 
                NUMBER_OF_POS_VOTES.append(np.sum(pos_itersections_with_all_neg/X_neg.shape[0] <= alpha))
                NUMBER_OF_NEG_VOTES.append(np.sum(neg_itersections_with_all_pos/X_pos.shape[0] <= alpha))
            print(datetime.datetime.now() - start_time)
            print("ENDED AT:", datetime.datetime.now())
            print("")
 
            df_result = pd.DataFrame({'POS_VOTES':NUMBER_OF_POS_VOTES,'NEG_VOTES':NUMBER_OF_NEG_VOTES,'y_true':y[mini_test_index]}, index=mini_test_index)
 
            FILE_NAME = str(NUMBER_OF_MINI_TEST)+".csv"
            DIR_NAME = MODIFICATION+str(number_of_iterations)+'_'+str(alpha)+'_'+str(subsample_size)
            PATH = ".\\"+DIR_NAME+"\\"+FILE_NAME
            df_result.to_csv(PATH)

# ##### Scores
 
# In[44]:
 
COL1 = []
COL2 = []
COL3 = []
COL4 = []
COL5 = []
COL6 = []
COL7 = []
COL8 = []
COL9 = []
COL10 = []
 
N_OF_ITER = []
ALPHA = []
SAMPLE_SIZES = []
 
 
# def generate_grid(N_OF_ITER,ALPHA,SAMPLE_SIZES):
#     X = [2000]
#     Y = [0.001, 0.002,0.003, 0.004, 0.005]
#     Z = [1,2,3,4,5]
#     for x in X:
#         for y in Y:
#             for z in Z:
#                 N_OF_ITER.append(x)
#                 ALPHA.append(y)
#                 SAMPLE_SIZES.append(z)
 
# generate_grid(N_OF_ITER,ALPHA,SAMPLE_SIZES)
 
# MODIFICATION = "concepts_"
MODIFICATION = ""
 
for dir_name in os.listdir():
    dir_name = dir_name.strip(MODIFICATION).split('_')
    if len(dir_name)==3 and str.isnumeric(dir_name[0]) and str.isnumeric(dir_name[2]):
        number_of_iterations = int(dir_name[0])
        alpha = float(dir_name[1])
        subsample_size = int(dir_name[2])
        # CONDITIONS. Что печатать?
#         if alpha == 0.002:
        if True:
            N_OF_ITER.append(number_of_iterations)
            ALPHA.append(alpha)
            SAMPLE_SIZES.append(subsample_size)
 
 
for number_of_iterations,alpha,subsample_size in zip(N_OF_ITER,ALPHA,SAMPLE_SIZES):
    DIR_NAME = MODIFICATION+str(number_of_iterations)+'_'+str(alpha)+'_'+str(subsample_size)
    result = pd.DataFrame()
    for NUMBER_OF_MINI_TEST in range(8):
        FILE_NAME = str(NUMBER_OF_MINI_TEST)+".csv"
        PATH = ".\\"+DIR_NAME+"\\"+FILE_NAME
        result_mini_test = pd.read_csv(PATH, index_col=0)
        result = pd.concat((result,result_mini_test))
 
 
    y_true = result.y_true
    num_of_unclassified = np.sum((result.NEG_VOTES == 0) & (result.POS_VOTES == 0))
 
    # Вычитаем голоса
    y_pred_diff = result.POS_VOTES*1 - result.NEG_VOTES*1
    y_pred_diff.loc[(result.NEG_VOTES == 0) & (result.POS_VOTES == 0)] = 0 # У КОГО СЧЕТ 0:0, тех относим к классу 0
#     y_pred_diff = 1 / (1 + np.exp(-y_pred_diff))
    y_pred_diff = y_pred_diff - np.min(y_pred_diff)/(np.max(y_pred_diff)-np.min(y_pred_diff))
    roc_auc_diff = sklearn.metrics.roc_auc_score(y_true,y_pred_diff)
 
    # Доля голосов
    y_pred_div = result.POS_VOTES*1/(result.POS_VOTES*1+result.NEG_VOTES*1)
    y_pred_div.loc[(result.NEG_VOTES == 0) & (result.POS_VOTES == 0)] = 0 # У КОГО СЧЕТ 0:0, тех относим к классу 0
    roc_auc_div = sklearn.metrics.roc_auc_score(y_true,y_pred_div)
 
 
    COL1.append(number_of_iterations)
    COL2.append(alpha)
    COL3.append(subsample_size)
    COL5.append(roc_auc_div)
    COL6.append(num_of_unclassified)
    COL7.append(roc_auc_diff)
# 'ROC-AUC':COL4
summary = pd.DataFrame({'number_of_iterations':COL1,'alpha':COL2,'subsample_size':COL3,                         'roc_auc_div':COL5,'roc_auc_diff':COL7,'num_of_unclassified':COL6
                       })
pd.set_option('display.max_rows', 1000)
summary.set_index(['number_of_iterations','alpha','subsample_size'])
 
 
# ##### MLCA (precalc concepts)
 
# The difference of this approach from the previous one is that premises are calculating beforehand.
# So there is no "bad" descriprions that are intersected with test objects.
 
# In[554]:
 
N_OF_NEEDED_CONCEPTS = [2000]
ALPHA = [0.002, 0.001]
SAMPLE_SIZES = [1]
MODIFICATION = "concepts_"
# MODIFICATION = "all_X_neg_"
 
 
for number_of_concepts in N_OF_NEEDED_CONCEPTS:
    for alpha in ALPHA:
        for subsample_size in SAMPLE_SIZES:
            os.system("mkdir "+ MODIFICATION +str(alpha)+'_'+str(subsample_size))
 
X_neg = X_neg_true
 
 
for alpha in ALPHA:
    for subsample_size in SAMPLE_SIZES:
        for number_of_concepts in N_OF_NEEDED_CONCEPTS:
 
            start_time = datetime.datetime.now()
            print("PARAMS: ", number_of_concepts, alpha, subsample_size)
            print("MINING PLUS (+) STARTED AT:", start_time.ctime())
 
            n_of_iter_pos = 0
            n_of_mined_concepts_pos = 0
 
            concepts_min = []
            concepts_max = []
            numbers_of_iter = [] # номер итерации, на которой мы получили этот концепт
            number_of_intersections = []
            while n_of_mined_concepts_pos < number_of_concepts:    
                n_of_iter_pos += 1
                pos_sample_ind = np.random.choice(X_pos.shape[0], size=subsample_size)
                while np.unique(pos_sample_ind).shape[0]!=subsample_size:
                    pos_sample_ind = np.random.choice(X_pos.shape[0], size=subsample_size)
                pos_sample = X_pos[pos_sample_ind]
                premise_min = pos_sample.min(axis=0)
                premise_max = pos_sample.max(axis=0)
                pos_itersections_with_all_neg=np.sum((np.sum(X_neg <= premise_max, axis=1) == 10) & (np.sum(X_neg >= premise_min, axis=1) == 10))
                if pos_itersections_with_all_neg/X_neg.shape[0] <= alpha:
                    concepts_min.append(premise_min)
                    concepts_max.append(premise_max)
                    numbers_of_iter.append(n_of_iter_pos)
                    number_of_intersections.append(pos_itersections_with_all_neg)
                    n_of_mined_concepts_pos += 1
 
 
            positive_concepts_min = pd.DataFrame(concepts_min, columns=df_train_pos.columns, index=np.arange(1,len(concepts_min)+1))
            positive_concepts_max = pd.DataFrame(concepts_max, columns=df_train_pos.columns, index=np.arange(1,len(concepts_max)+1))
            positive_n_iter = pd.Series(numbers_of_iter, index=np.arange(1,len(numbers_of_iter)+1))
            positive_n_intersections_with_neg = pd.Series(number_of_intersections, index=np.arange(1,len(numbers_of_iter)+1))
 
            DIR_NAME = MODIFICATION+str(alpha)+'_'+str(subsample_size)
            PATH = ".\\"+DIR_NAME+"\\"
            positive_concepts_min.to_csv(PATH+str(number_of_concepts)+'_'+"positive_concepts_min.csv")
            positive_concepts_max.to_csv(PATH+str(number_of_concepts)+'_'+"positive_concepts_max.csv")
            positive_n_iter.to_csv(PATH+str(number_of_concepts)+'_'+"positive_n_iter.csv")
            positive_n_intersections_with_neg.to_csv(PATH+str(number_of_concepts)+'_'+"positive_n_intersections_with_neg.csv")
 
            print(datetime.datetime.now() - start_time)
            print("MINING PLUS (+) ENDED AT:", datetime.datetime.now())
            print("")    
 
            ############################
 
            start_time = datetime.datetime.now()
            print("PARAMS: ", number_of_concepts, alpha, subsample_size)
            print("MINING MINUS (-) STARTED AT:", start_time.ctime())
 
            n_of_iter_neg = 0
            n_of_mined_concepts_neg = 0
 
            concepts_min = []
            concepts_max = []
            numbers_of_iter = [] # номер итерации, на которой мы получили этот концепт
            number_of_intersections = []
            while n_of_mined_concepts_neg < number_of_concepts:    
                n_of_iter_neg += 1
                neg_sample_ind = np.random.choice(X_neg.shape[0], size=subsample_size)
                while np.unique(neg_sample_ind).shape[0]!=subsample_size:
                    neg_sample_ind = np.random.choice(X_neg.shape[0], size=subsample_size)
                neg_sample = X_neg[neg_sample_ind]
                premise_min = neg_sample.min(axis=0)
                premise_max = neg_sample.max(axis=0)
                neg_itersections_with_all_pos=np.sum((np.sum(X_pos <= premise_max, axis=1) == 10) & (np.sum(X_pos >= premise_min, axis=1) == 10))
                if neg_itersections_with_all_pos/X_pos.shape[0] <= alpha:
                    concepts_min.append(premise_min)
                    concepts_max.append(premise_max)
                    numbers_of_iter.append(n_of_iter_neg)
                    number_of_intersections.append(neg_itersections_with_all_pos)
                    n_of_mined_concepts_neg += 1
 
 
            negative_concepts_min = pd.DataFrame(concepts_min, columns=df_train_neg.columns, index=np.arange(1,len(concepts_min)+1))
            negative_concepts_max = pd.DataFrame(concepts_max, columns=df_train_neg.columns, index=np.arange(1,len(concepts_max)+1))
            negative_n_iter = pd.Series(numbers_of_iter, index=np.arange(1,len(numbers_of_iter)+1))
            negative_n_intersections_with_neg = pd.Series(number_of_intersections, index=np.arange(1,len(numbers_of_iter)+1))
 
            DIR_NAME = MODIFICATION+str(alpha)+'_'+str(subsample_size)
            PATH = ".\\"+DIR_NAME+"\\"
            negative_concepts_min.to_csv(PATH+str(number_of_concepts)+'_'+"negative_concepts_min.csv")
            negative_concepts_max.to_csv(PATH+str(number_of_concepts)+'_'+"negative_concepts_max.csv")
            negative_n_iter.to_csv(PATH+str(number_of_concepts)+'_'+"negative_n_iter.csv")
            negative_n_intersections_with_neg.to_csv(PATH+str(number_of_concepts)+'_'+"negative_n_intersections_with_neg.csv")
 
            print(datetime.datetime.now() - start_time)
            print("MINING MINUS (-) ENDED AT:", datetime.datetime.now())
            print("")           
 
 
#             df_result = pd.DataFrame({'POS_VOTES':NUMBER_OF_POS_VOTES,'NEG_VOTES':NUMBER_OF_NEG_VOTES,'y_true':y[mini_test_index]}, index=mini_test_index)
 
#             FILE_NAME = str(NUMBER_OF_MINI_TEST)+".csv"
#             DIR_NAME = MODIFICATION+str(number_of_iterations)+'_'+str(alpha)+'_'+str(subsample_size)
#             PATH = ".\\"+DIR_NAME+"\\"+FILE_NAME
#             df_result.to_csv(PATH)
 
 
# ###### Classifying test objects
 
# In[567]:
 
ALPHA = [0.003]
SAMPLE_SIZES = [1,2,3,4,5]
N_OF_NEEDED_CONCEPTS = [2000]
 
for alpha in ALPHA:
    for subsample_size in SAMPLE_SIZES:
        for number_of_concepts in N_OF_NEEDED_CONCEPTS:
 
            start_time = datetime.datetime.now()
            print("PARAMS: ", number_of_concepts, alpha, subsample_size)
            print("MINING PLUS (+) STARTED AT:", start_time.ctime())
 
            DIR_NAME = "concepts_"+str(alpha)+'_'+str(subsample_size)
            PATH = ".\\"+DIR_NAME+"\\"
            positive_concepts_min = pd.read_csv(PATH+str(number_of_concepts)+'_'+"positive_concepts_min.csv",index_col=0).values
            positive_concepts_max = pd.read_csv(PATH+str(number_of_concepts)+'_'+"positive_concepts_max.csv",index_col=0).values
            negative_concepts_min = pd.read_csv(PATH+str(number_of_concepts)+'_'+"negative_concepts_min.csv",index_col=0).values
            negative_concepts_max = pd.read_csv(PATH+str(number_of_concepts)+'_'+"negative_concepts_max.csv",index_col=0).values
 
            positive_n_intersections_with_neg = pd.read_csv(PATH+str(number_of_concepts)+'_'+"positive_n_intersections_with_neg.csv",index_col=0, header=-1).values[:,0]
            negative_n_intersections_with_pos = pd.read_csv(PATH+str(number_of_concepts)+'_'+"negative_n_intersections_with_neg.csv",index_col=0, header=-1).values[:,0]
 
 
            NUMBER_OF_MINI_TEST = 0
 
            mini_test_size = df_test.shape[0]//8
            start_index = mini_test_size*NUMBER_OF_MINI_TEST
            end_index = start_index+mini_test_size
            mini_test_index = df_test.index[start_index:end_index]
 
            NUMBER_OF_POS_VOTES = []
            NUMBER_OF_NEG_VOTES = []
            start_time = datetime.datetime.now()
            for test_index in mini_test_index:
                test_obj = df_test.loc[test_index].values
 
                neg_itersections_with_all_pos = np.zeros(number_of_concepts)
                pos_itersections_with_all_neg = np.zeros(number_of_concepts)
                X_neg = X_neg_true[np.random.choice(X_neg_true.shape[0], size=X_pos.shape[0], replace=False)]
 
                premises_min = np.minimum(positive_concepts_min,test_obj)
                premises_max = np.maximum(positive_concepts_max,test_obj)
                premises = np.concatenate((premises_min,  premises_max), axis=1)
                pos_itersections_with_all_neg = np.apply_along_axis(lambda row: np.sum( ((row[:10] <= X_neg) & (X_neg <= row[10:])).all(axis=1) ), 1, premises)
 
                premises_min = np.minimum(negative_concepts_min,test_obj)
                premises_max = np.maximum(negative_concepts_max,test_obj)
                premises = np.concatenate((premises_min,  premises_max), axis=1)
                neg_itersections_with_all_pos = np.apply_along_axis(lambda row: np.sum( ((row[:10] <= X_pos) & (X_pos <= row[10:])).all(axis=1) ), 1, premises)
 
 
                NUMBER_OF_POS_VOTES.append(np.sum(pos_itersections_with_all_neg/X_neg.shape[0] <= alpha))
                NUMBER_OF_NEG_VOTES.append(np.sum(neg_itersections_with_all_pos/X_pos.shape[0] <= alpha))
 
 
            df_result = pd.DataFrame({'POS_VOTES':NUMBER_OF_POS_VOTES,'NEG_VOTES':NUMBER_OF_NEG_VOTES,'y_true':y[mini_test_index]}, index=mini_test_index)
 
 
            FILE_NAME = str(NUMBER_OF_MINI_TEST)+".csv"
            PATH = ".\\"+DIR_NAME+"\\"+FILE_NAME
            df_result.to_csv(PATH)
 
            print(datetime.datetime.now() - start_time)
            print("ENDED AT:", datetime.datetime.now())
            print("")
 
 
# In[50]:
 
COL1 = []
COL2 = []
COL3 = []
COL4 = []
COL5 = []
COL6 = []
COL7 = []
COL8 = []
COL9 = []
COL10 = []
 
N_OF_ITER = []
ALPHA = []
SAMPLE_SIZES = []
 
 
def generate_grid(N_OF_ITER,ALPHA,SAMPLE_SIZES):
    X = [2000]
    Y = [0.001, 0.002,0.003, 0.004, 0.005]
    Z = [1,2,3,4,5]
    for x in X:
        for y in Y:
            for z in Z:
                N_OF_ITER.append(x)
                ALPHA.append(y)
                SAMPLE_SIZES.append(z)
 
generate_grid(N_OF_ITER,ALPHA,SAMPLE_SIZES)
 
MODIFICATION = "concepts_"
# MODIFICATION = ""
 
# for dir_name in os.listdir():
#     dir_name = dir_name.strip(MODIFICATION).split('_')
#     if len(dir_name)==3 and str.isnumeric(dir_name[0]) and str.isnumeric(dir_name[2]):
#         number_of_iterations = int(dir_name[0])
#         alpha = float(dir_name[1])
#         subsample_size = int(dir_name[2])
#         # CONDITIONS. Что печатать?
# #         if alpha >= 0.002 and alpha <= 0.005:
#         if True:
#             N_OF_ITER.append(number_of_iterations)
#             ALPHA.append(alpha)
#             SAMPLE_SIZES.append(subsample_size)
 
 
for number_of_iterations,alpha,subsample_size in zip(N_OF_ITER,ALPHA,SAMPLE_SIZES):
    DIR_NAME = MODIFICATION+str(alpha)+'_'+str(subsample_size)
    result = pd.DataFrame()
    for NUMBER_OF_MINI_TEST in range(8):
        FILE_NAME = str(NUMBER_OF_MINI_TEST)+".csv"
        PATH = ".\\"+DIR_NAME+"\\"+FILE_NAME
        result_mini_test = pd.read_csv(PATH, index_col=0)
        result = pd.concat((result,result_mini_test))
 
 
    y_true = result.y_true
    num_of_unclassified = np.sum((result.NEG_VOTES == 0) & (result.POS_VOTES == 0))
 
    # Вычитаем голоса
    y_pred_diff = result.POS_VOTES*1 - result.NEG_VOTES*1
    y_pred_diff.loc[(result.NEG_VOTES == 0) & (result.POS_VOTES == 0)] = 0 # У КОГО СЧЕТ 0:0, тех относим к классу 0
#     y_pred_diff = 1 / (1 + np.exp(-y_pred_diff))
    y_pred_diff = y_pred_diff - np.min(y_pred_diff)/(np.max(y_pred_diff)-np.min(y_pred_diff))
    roc_auc_diff = sklearn.metrics.roc_auc_score(y_true,y_pred_diff)
 
    # Доля голосов
    y_pred_div = result.POS_VOTES*1/(result.POS_VOTES*1+result.NEG_VOTES*1)
    y_pred_div.loc[(result.NEG_VOTES == 0) & (result.POS_VOTES == 0)] = 0 # У КОГО СЧЕТ 0:0, тех относим к классу 0
    roc_auc_div = sklearn.metrics.roc_auc_score(y_true,y_pred_div)
 
 
    COL1.append(number_of_iterations)
    COL2.append(alpha)
    COL3.append(subsample_size)
#             COL4.append(roc_auc)
    COL5.append(roc_auc_div)
    COL6.append(num_of_unclassified)
    COL7.append(roc_auc_diff)
# 'ROC-AUC':COL4
summary = pd.DataFrame({'number_of_iterations':COL1,'alpha':COL2,'subsample_size':COL3,                         'roc_auc_div':COL5,'roc_auc_diff':COL7,'num_of_unclassified':COL6
                       })
pd.set_option('display.max_rows', 1000)
summary.set_index(['number_of_iterations','alpha','subsample_size'])
 
 
# ##### Classifying objects with missing data
 
# In[624]:
 
df_na = pd.read_csv('cs-training.csv', index_col=0)
df_na = df_na[df_na.MonthlyIncome.isnull()]
df_na.shape
 
 
# In[628]:
 
df_na_pos = df_na[df_na.SeriousDlqin2yrs == 1]
df_na_minus = df_na.drop(df_na_pos.index)
df_na_pos_test = df_na_pos.sample(frac=0.1, random_state=1)
df_na_neg_test = df_na_minus.sample(frac=0.1, random_state=1)
df_na_test = df_na_pos_test.append(df_na_neg_test)
 
 
# In[636]:
 
# df_na_test.to_csv('df_na_test.csv')
 
 
# In[643]:
 
df_na_test = pd.read_csv('df_na_test.csv', index_col=0)
y_na_true = df_na_test.SeriousDlqin2yrs
df_na_test = df_na_test.drop('SeriousDlqin2yrs', axis=1)
 
 
# In[843]:
 
df_na_test = pd.read_csv('cs-test.csv', index_col=0)
y_na_true = df_na_test.SeriousDlqin2yrs
df_na_test = df_na_test.drop('SeriousDlqin2yrs', axis=1)
 
ALPHA = [0.001]
SAMPLE_SIZES = [3]
N_OF_NEEDED_CONCEPTS = [2000]
 
for alpha in ALPHA:
    for subsample_size in SAMPLE_SIZES:
        for number_of_concepts in N_OF_NEEDED_CONCEPTS:
 
            start_time = datetime.datetime.now()
            print("PARAMS: ", number_of_concepts, alpha, subsample_size)
            print("MINING PLUS (+) STARTED AT:", start_time.ctime())
 
            DIR_NAME = "concepts_"+str(alpha)+'_'+str(subsample_size)
            PATH = ".\\"+DIR_NAME+"\\"
            positive_concepts_min = pd.read_csv(PATH+str(number_of_concepts)+'_'+"positive_concepts_min.csv",index_col=0).values
            positive_concepts_max = pd.read_csv(PATH+str(number_of_concepts)+'_'+"positive_concepts_max.csv",index_col=0).values
            negative_concepts_min = pd.read_csv(PATH+str(number_of_concepts)+'_'+"negative_concepts_min.csv",index_col=0).values
            negative_concepts_max = pd.read_csv(PATH+str(number_of_concepts)+'_'+"negative_concepts_max.csv",index_col=0).values
 
            positive_n_intersections_with_neg = pd.read_csv(PATH+str(number_of_concepts)+'_'+"positive_n_intersections_with_neg.csv",index_col=0, header=-1).values[:,0]
            negative_n_intersections_with_pos = pd.read_csv(PATH+str(number_of_concepts)+'_'+"negative_n_intersections_with_neg.csv",index_col=0, header=-1).values[:,0]
 
 
            NUMBER_OF_MINI_TEST = 0
 
            mini_test_size = df_na_test.shape[0]//8
            start_index = mini_test_size*NUMBER_OF_MINI_TEST
            end_index = start_index+mini_test_size
            mini_test_index = df_na_test.index[start_index:end_index]
 
            NUMBER_OF_POS_VOTES = []
            NUMBER_OF_NEG_VOTES = []
            start_time = datetime.datetime.now()
            for test_index in mini_test_index:
                test_obj = df_na_test.loc[test_index].values
 
                neg_itersections_with_all_pos = np.zeros(number_of_concepts)
                pos_itersections_with_all_neg = np.zeros(number_of_concepts)
                X_neg = X_neg_true[np.random.choice(X_neg_true.shape[0], size=X_pos.shape[0], replace=False)]
 
                test_obj_max = test_obj.copy()
                test_obj_max[np.isnan(test_obj_max)] = np.inf
                test_obj_min = test_obj.copy()
                test_obj_min[np.isnan(test_obj_min)] = -np.inf
 
                premises_min = np.minimum(positive_concepts_min,test_obj_min)
                premises_max = np.maximum(positive_concepts_max,test_obj_max)
                premises = np.concatenate((premises_min,  premises_max), axis=1)
                pos_itersections_with_all_neg = np.apply_along_axis(lambda row: np.sum( ((row[:10] <= X_neg) & (X_neg <= row[10:])).all(axis=1) ), 1, premises)
 
                premises_min = np.minimum(negative_concepts_min,test_obj_min)
                premises_max = np.maximum(negative_concepts_max,test_obj_max)
                premises = np.concatenate((premises_min,  premises_max), axis=1)
                neg_itersections_with_all_pos = np.apply_along_axis(lambda row: np.sum( ((row[:10] <= X_pos) & (X_pos <= row[10:])).all(axis=1) ), 1, premises)
 
 
                NUMBER_OF_POS_VOTES.append(np.sum(pos_itersections_with_all_neg/X_neg.shape[0] <= alpha))
                NUMBER_OF_NEG_VOTES.append(np.sum(neg_itersections_with_all_pos/X_pos.shape[0] <= alpha))
 
 
            df_result = pd.DataFrame({'POS_VOTES':NUMBER_OF_POS_VOTES,'NEG_VOTES':NUMBER_OF_NEG_VOTES,'y_true':y_na_true[mini_test_index]}, index=mini_test_index)
 
 
            FILE_NAME = 'na_'+str(NUMBER_OF_MINI_TEST)+".csv"
            PATH = ".\\"+DIR_NAME+"\\"+FILE_NAME
            df_result.to_csv(PATH)
 
            print(datetime.datetime.now() - start_time)
            print("ENDED AT:", datetime.datetime.now())
            print("")
 
 
# In[34]:
 
COL1 = []
COL2 = []
COL3 = []
COL4 = []
COL5 = []
COL6 = []
COL7 = []
COL8 = []
COL9 = []
COL10 = []
 
N_OF_ITER = []
ALPHA = []
SAMPLE_SIZES = []
 
 
# def generate_grid(N_OF_ITER,ALPHA,SAMPLE_SIZES):
#     X = [2000]
#     Y = [0.001, 0.002,0.003, 0.004, 0.005]
#     Z = [1,2,3,4,5]
#     for x in X:
#         for y in Y:
#             for z in Z:
#                 N_OF_ITER.append(x)
#                 ALPHA.append(y)
#                 SAMPLE_SIZES.append(z)
 
# generate_grid(N_OF_ITER,ALPHA,SAMPLE_SIZES)
 
MODIFICATION = "concepts_"
# MODIFICATION = ""
 
for dir_name in os.listdir():
    dir_name = dir_name.strip(MODIFICATION).split('_')
    if len(dir_name)==3 and str.isnumeric(dir_name[0]) and str.isnumeric(dir_name[2]):
        number_of_iterations = int(dir_name[0])
        alpha = float(dir_name[1])
        subsample_size = int(dir_name[2])
        # CONDITIONS. Что печатать?
        if alpha >= 0.002 and alpha <= 0.005:
#         if True:
            N_OF_ITER.append(number_of_iterations)
            ALPHA.append(alpha)
            SAMPLE_SIZES.append(subsample_size)
 
 
for number_of_iterations,alpha,subsample_size in zip(N_OF_ITER,ALPHA,SAMPLE_SIZES):
    DIR_NAME = MODIFICATION+str(alpha)+'_'+str(subsample_size)
    result = pd.DataFrame()
    for NUMBER_OF_MINI_TEST in range(8):
        FILE_NAME = "na_"+str(NUMBER_OF_MINI_TEST)+".csv"
        PATH = ".\\"+DIR_NAME+"\\"+FILE_NAME
        result_mini_test = pd.read_csv(PATH, index_col=0)
        result = pd.concat((result,result_mini_test))
 
 
    y_true = result.y_true
    num_of_unclassified = np.sum((result.NEG_VOTES == 0) & (result.POS_VOTES == 0))
 
    # Вычитаем голоса
    y_pred_diff = result.POS_VOTES*1 - result.NEG_VOTES*1
    y_pred_diff.loc[(result.NEG_VOTES == 0) & (result.POS_VOTES == 0)] = 0 # У КОГО СЧЕТ 0:0, тех относим к классу 0
#     y_pred_diff = 1 / (1 + np.exp(-y_pred_diff))
    y_pred_diff = y_pred_diff - np.min(y_pred_diff)/(np.max(y_pred_diff)-np.min(y_pred_diff))
    roc_auc_diff = sklearn.metrics.roc_auc_score(y_true,y_pred_diff)
 
    # Доля голосов
    y_pred_div = result.POS_VOTES*1/(result.POS_VOTES*1+result.NEG_VOTES*1)
    y_pred_div.loc[(result.NEG_VOTES == 0) & (result.POS_VOTES == 0)] = 0 # У КОГО СЧЕТ 0:0, тех относим к классу 0
    roc_auc_div = sklearn.metrics.roc_auc_score(y_true,y_pred_div)
 
 
    COL1.append(number_of_iterations)
    COL2.append(alpha)
    COL3.append(subsample_size)
#             COL4.append(roc_auc)
    COL5.append(roc_auc_div)
    COL6.append(num_of_unclassified)
    COL7.append(roc_auc_diff)
# 'ROC-AUC':COL4
summary = pd.DataFrame({'number_of_iterations':COL1,'alpha':COL2,'subsample_size':COL3,                         'roc_auc_div':COL5,'roc_auc_diff':COL7,'num_of_unclassified':COL6
                       })
pd.set_option('display.max_rows', 1000)
summary.set_index(['number_of_iterations','alpha','subsample_size'])
 
 
# ### Logistic regression
 
# In[19]:
 
df_train = df.drop(df_test.index).drop('SeriousDlqin2yrs', axis=1)
y_train_true = y[df_train.index]
y_test_true = y[df_test.index]
 
 
# In[54]:
 
from sklearn import linear_model
from sklearn import metrics
X = df_train.values
 
for C in [10**i for i in range(-10,10)]:
    LR = linear_model.LogisticRegression(C=C, penalty='l1')
    LR.fit(X,y_train_true)
    print("C=",C," ","L=L1",end="\t\t")
    print("Train score",sklearn.metrics.roc_auc_score(y_train_true, LR.predict_proba(X)[:,1]), end="\t")
    print("Test score",sklearn.metrics.roc_auc_score(y_test_true, LR.predict_proba(X_test)[:,1]))
 
 
for C in [10**i for i in range(-10,10)]:
    LR = linear_model.LogisticRegression(C=C, penalty='l2')
    LR.fit(X,y_train_true)
    print("C=",C," ","L=L2",end="\t\t")
    print("Train score",sklearn.metrics.roc_auc_score(y_train_true, LR.predict_proba(X)[:,1]), end="\t")
    print("Test score",sklearn.metrics.roc_auc_score(y_test_true, LR.predict_proba(X_test)[:,1]))
 
 
# ### Random forest
 
# In[ ]:
 
from sklearn import ensemble
from sklearn import metrics
X = df_train.values
ensemble.RandomForestClassifier()
for n_of_est in [10,50,100,200,500,1000]:
    RF = ensemble.RandomForestClassifier(n_estimators=n_of_est, n_jobs=8)
    RF.fit(X,y_train_true)
    print("n_estimators=",n_of_est,end="\t\t")
    print("Train score",sklearn.metrics.roc_auc_score(y_train_true, RF.predict_proba(X)[:,1]), end="\t")
    print("Test score",sklearn.metrics.roc_auc_score(y_test_true, RF.predict_proba(X_test)[:,1]))
 
 
# ### 5. Comparison of the results
 
# MLCA and Random forest showed comparable results: AUC_ROC = $~0.84$.
# 
# It's much more than logistic regression: AUC_ROC = $~0.68$.
 
# MLCA with best parameters was applied to Kaggle's test dataset (more than 100k objects including objects with missing data). The result AUC_ROC was approximately the same 0.843510.
 
# In the future one can perform data cleaning and crossvalidation that probably improve the quality of the classifier.